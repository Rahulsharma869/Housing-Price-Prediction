{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.activations import linear, relu, sigmoid","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-23T04:43:22.221677Z","iopub.execute_input":"2023-04-23T04:43:22.222123Z","iopub.status.idle":"2023-04-23T04:43:30.827493Z","shell.execute_reply.started":"2023-04-23T04:43:22.222081Z","shell.execute_reply":"2023-04-23T04:43:30.826251Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"train_url  = \"https://raw.githubusercontent.com/Rahulsharma869/Housing-Price-Prediction/main/Datasets/train.csv\"\ntrain_set = pd.read_csv(train_url)\ntrain_set","metadata":{"execution":{"iopub.status.busy":"2023-04-23T04:43:30.829293Z","iopub.execute_input":"2023-04-23T04:43:30.829982Z","iopub.status.idle":"2023-04-23T04:43:31.077609Z","shell.execute_reply.started":"2023-04-23T04:43:30.829942Z","shell.execute_reply":"2023-04-23T04:43:31.076347Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"        Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n0        1          60       RL         65.0     8450   Pave   NaN      Reg   \n1        2          20       RL         80.0     9600   Pave   NaN      Reg   \n2        3          60       RL         68.0    11250   Pave   NaN      IR1   \n3        4          70       RL         60.0     9550   Pave   NaN      IR1   \n4        5          60       RL         84.0    14260   Pave   NaN      IR1   \n...    ...         ...      ...          ...      ...    ...   ...      ...   \n1455  1456          60       RL         62.0     7917   Pave   NaN      Reg   \n1456  1457          20       RL         85.0    13175   Pave   NaN      Reg   \n1457  1458          70       RL         66.0     9042   Pave   NaN      Reg   \n1458  1459          20       RL         68.0     9717   Pave   NaN      Reg   \n1459  1460          20       RL         75.0     9937   Pave   NaN      Reg   \n\n     LandContour Utilities  ... PoolArea PoolQC  Fence MiscFeature MiscVal  \\\n0            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n1            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n2            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n3            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n4            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n...          ...       ...  ...      ...    ...    ...         ...     ...   \n1455         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n1456         Lvl    AllPub  ...        0    NaN  MnPrv         NaN       0   \n1457         Lvl    AllPub  ...        0    NaN  GdPrv        Shed    2500   \n1458         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n1459         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n\n     MoSold YrSold  SaleType  SaleCondition  SalePrice  \n0         2   2008        WD         Normal     208500  \n1         5   2007        WD         Normal     181500  \n2         9   2008        WD         Normal     223500  \n3         2   2006        WD        Abnorml     140000  \n4        12   2008        WD         Normal     250000  \n...     ...    ...       ...            ...        ...  \n1455      8   2007        WD         Normal     175000  \n1456      2   2010        WD         Normal     210000  \n1457      5   2010        WD         Normal     266500  \n1458      4   2010        WD         Normal     142125  \n1459      6   2008        WD         Normal     147500  \n\n[1460 rows x 81 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>MSSubClass</th>\n      <th>MSZoning</th>\n      <th>LotFrontage</th>\n      <th>LotArea</th>\n      <th>Street</th>\n      <th>Alley</th>\n      <th>LotShape</th>\n      <th>LandContour</th>\n      <th>Utilities</th>\n      <th>...</th>\n      <th>PoolArea</th>\n      <th>PoolQC</th>\n      <th>Fence</th>\n      <th>MiscFeature</th>\n      <th>MiscVal</th>\n      <th>MoSold</th>\n      <th>YrSold</th>\n      <th>SaleType</th>\n      <th>SaleCondition</th>\n      <th>SalePrice</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>65.0</td>\n      <td>8450</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>208500</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>80.0</td>\n      <td>9600</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>5</td>\n      <td>2007</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>181500</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>68.0</td>\n      <td>11250</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>9</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>223500</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>70</td>\n      <td>RL</td>\n      <td>60.0</td>\n      <td>9550</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2006</td>\n      <td>WD</td>\n      <td>Abnorml</td>\n      <td>140000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>84.0</td>\n      <td>14260</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>12</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>250000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1455</th>\n      <td>1456</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>62.0</td>\n      <td>7917</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>8</td>\n      <td>2007</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>175000</td>\n    </tr>\n    <tr>\n      <th>1456</th>\n      <td>1457</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>85.0</td>\n      <td>13175</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>MnPrv</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2010</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>210000</td>\n    </tr>\n    <tr>\n      <th>1457</th>\n      <td>1458</td>\n      <td>70</td>\n      <td>RL</td>\n      <td>66.0</td>\n      <td>9042</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>GdPrv</td>\n      <td>Shed</td>\n      <td>2500</td>\n      <td>5</td>\n      <td>2010</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>266500</td>\n    </tr>\n    <tr>\n      <th>1458</th>\n      <td>1459</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>68.0</td>\n      <td>9717</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>4</td>\n      <td>2010</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>142125</td>\n    </tr>\n    <tr>\n      <th>1459</th>\n      <td>1460</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>75.0</td>\n      <td>9937</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>6</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>147500</td>\n    </tr>\n  </tbody>\n</table>\n<p>1460 rows × 81 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"xtrain_col = [\"MSSubClass\",\n             \"LotArea\",\n             \"OverallQual\",\n             \"OverallCond\",\n             \"YearBuilt\",\n             \"YearRemodAdd\",\n             \"TotalBsmtSF\",\n             \"1stFlrSF\",\n             \"2ndFlrSF\",\n             \"GrLivArea\",\n             \"BedroomAbvGr\",\n             \"KitchenAbvGr\",\n             \"GarageCars\",\n             \"GarageArea\",\n             \"PoolArea\",\n             \"MoSold\",\n             \"PoolArea\",\n             \"YrSold\"]\nxtrain = train_set.loc[:,xtrain_col]\nytrain = train_set.loc[:,\"SalePrice\"]\nsmall_nonzero = 0.001\n#xtrain = np.where(xtrain == 0, small_nonzero, xtrain)\nprint(f'xtrain : {xtrain.shape}')\nprint(f'ytrain : {ytrain.shape}')\n#print(xtrain)\n#print(ytrain)\nsplit = int(1468*0.8)\nx_train = np.array(xtrain[:split])\ny_train = np.array(ytrain[:split])\nx_test = np.array(xtrain[split:])\ny_test = np.array(ytrain[split:])\nxtrain","metadata":{"execution":{"iopub.status.busy":"2023-04-23T04:43:31.079140Z","iopub.execute_input":"2023-04-23T04:43:31.079596Z","iopub.status.idle":"2023-04-23T04:43:31.109624Z","shell.execute_reply.started":"2023-04-23T04:43:31.079545Z","shell.execute_reply":"2023-04-23T04:43:31.108466Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"xtrain : (1460, 18)\nytrain : (1460,)\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"      MSSubClass  LotArea  OverallQual  OverallCond  YearBuilt  YearRemodAdd  \\\n0             60     8450            7            5       2003          2003   \n1             20     9600            6            8       1976          1976   \n2             60    11250            7            5       2001          2002   \n3             70     9550            7            5       1915          1970   \n4             60    14260            8            5       2000          2000   \n...          ...      ...          ...          ...        ...           ...   \n1455          60     7917            6            5       1999          2000   \n1456          20    13175            6            6       1978          1988   \n1457          70     9042            7            9       1941          2006   \n1458          20     9717            5            6       1950          1996   \n1459          20     9937            5            6       1965          1965   \n\n      TotalBsmtSF  1stFlrSF  2ndFlrSF  GrLivArea  BedroomAbvGr  KitchenAbvGr  \\\n0             856       856       854       1710             3             1   \n1            1262      1262         0       1262             3             1   \n2             920       920       866       1786             3             1   \n3             756       961       756       1717             3             1   \n4            1145      1145      1053       2198             4             1   \n...           ...       ...       ...        ...           ...           ...   \n1455          953       953       694       1647             3             1   \n1456         1542      2073         0       2073             3             1   \n1457         1152      1188      1152       2340             4             1   \n1458         1078      1078         0       1078             2             1   \n1459         1256      1256         0       1256             3             1   \n\n      GarageCars  GarageArea  PoolArea  MoSold  PoolArea  YrSold  \n0              2         548         0       2         0    2008  \n1              2         460         0       5         0    2007  \n2              2         608         0       9         0    2008  \n3              3         642         0       2         0    2006  \n4              3         836         0      12         0    2008  \n...          ...         ...       ...     ...       ...     ...  \n1455           2         460         0       8         0    2007  \n1456           2         500         0       2         0    2010  \n1457           1         252         0       5         0    2010  \n1458           1         240         0       4         0    2010  \n1459           1         276         0       6         0    2008  \n\n[1460 rows x 18 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MSSubClass</th>\n      <th>LotArea</th>\n      <th>OverallQual</th>\n      <th>OverallCond</th>\n      <th>YearBuilt</th>\n      <th>YearRemodAdd</th>\n      <th>TotalBsmtSF</th>\n      <th>1stFlrSF</th>\n      <th>2ndFlrSF</th>\n      <th>GrLivArea</th>\n      <th>BedroomAbvGr</th>\n      <th>KitchenAbvGr</th>\n      <th>GarageCars</th>\n      <th>GarageArea</th>\n      <th>PoolArea</th>\n      <th>MoSold</th>\n      <th>PoolArea</th>\n      <th>YrSold</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>60</td>\n      <td>8450</td>\n      <td>7</td>\n      <td>5</td>\n      <td>2003</td>\n      <td>2003</td>\n      <td>856</td>\n      <td>856</td>\n      <td>854</td>\n      <td>1710</td>\n      <td>3</td>\n      <td>1</td>\n      <td>2</td>\n      <td>548</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2008</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20</td>\n      <td>9600</td>\n      <td>6</td>\n      <td>8</td>\n      <td>1976</td>\n      <td>1976</td>\n      <td>1262</td>\n      <td>1262</td>\n      <td>0</td>\n      <td>1262</td>\n      <td>3</td>\n      <td>1</td>\n      <td>2</td>\n      <td>460</td>\n      <td>0</td>\n      <td>5</td>\n      <td>0</td>\n      <td>2007</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>60</td>\n      <td>11250</td>\n      <td>7</td>\n      <td>5</td>\n      <td>2001</td>\n      <td>2002</td>\n      <td>920</td>\n      <td>920</td>\n      <td>866</td>\n      <td>1786</td>\n      <td>3</td>\n      <td>1</td>\n      <td>2</td>\n      <td>608</td>\n      <td>0</td>\n      <td>9</td>\n      <td>0</td>\n      <td>2008</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>70</td>\n      <td>9550</td>\n      <td>7</td>\n      <td>5</td>\n      <td>1915</td>\n      <td>1970</td>\n      <td>756</td>\n      <td>961</td>\n      <td>756</td>\n      <td>1717</td>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>642</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2006</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>60</td>\n      <td>14260</td>\n      <td>8</td>\n      <td>5</td>\n      <td>2000</td>\n      <td>2000</td>\n      <td>1145</td>\n      <td>1145</td>\n      <td>1053</td>\n      <td>2198</td>\n      <td>4</td>\n      <td>1</td>\n      <td>3</td>\n      <td>836</td>\n      <td>0</td>\n      <td>12</td>\n      <td>0</td>\n      <td>2008</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1455</th>\n      <td>60</td>\n      <td>7917</td>\n      <td>6</td>\n      <td>5</td>\n      <td>1999</td>\n      <td>2000</td>\n      <td>953</td>\n      <td>953</td>\n      <td>694</td>\n      <td>1647</td>\n      <td>3</td>\n      <td>1</td>\n      <td>2</td>\n      <td>460</td>\n      <td>0</td>\n      <td>8</td>\n      <td>0</td>\n      <td>2007</td>\n    </tr>\n    <tr>\n      <th>1456</th>\n      <td>20</td>\n      <td>13175</td>\n      <td>6</td>\n      <td>6</td>\n      <td>1978</td>\n      <td>1988</td>\n      <td>1542</td>\n      <td>2073</td>\n      <td>0</td>\n      <td>2073</td>\n      <td>3</td>\n      <td>1</td>\n      <td>2</td>\n      <td>500</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2010</td>\n    </tr>\n    <tr>\n      <th>1457</th>\n      <td>70</td>\n      <td>9042</td>\n      <td>7</td>\n      <td>9</td>\n      <td>1941</td>\n      <td>2006</td>\n      <td>1152</td>\n      <td>1188</td>\n      <td>1152</td>\n      <td>2340</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>252</td>\n      <td>0</td>\n      <td>5</td>\n      <td>0</td>\n      <td>2010</td>\n    </tr>\n    <tr>\n      <th>1458</th>\n      <td>20</td>\n      <td>9717</td>\n      <td>5</td>\n      <td>6</td>\n      <td>1950</td>\n      <td>1996</td>\n      <td>1078</td>\n      <td>1078</td>\n      <td>0</td>\n      <td>1078</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>240</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>2010</td>\n    </tr>\n    <tr>\n      <th>1459</th>\n      <td>20</td>\n      <td>9937</td>\n      <td>5</td>\n      <td>6</td>\n      <td>1965</td>\n      <td>1965</td>\n      <td>1256</td>\n      <td>1256</td>\n      <td>0</td>\n      <td>1256</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>276</td>\n      <td>0</td>\n      <td>6</td>\n      <td>0</td>\n      <td>2008</td>\n    </tr>\n  </tbody>\n</table>\n<p>1460 rows × 18 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from tensorflow.keras import regularizers\nmodel = Sequential(\n    [               \n        Dense(20, activation='relu', name = 'layer1',input_shape=(18,),kernel_regularizer=regularizers.l2(0.01)),\n        Dense(10, activation='relu', name = 'layer2',kernel_regularizer=regularizers.l2(0.01)),\n        Dense(5, activation='relu', name = 'layer3',kernel_regularizer=regularizers.l2(0.01)),\n        Dense(1, activation='relu', name = 'layer4')\n    ], name = \"my_model\" \n)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-04-23T04:43:31.112222Z","iopub.execute_input":"2023-04-23T04:43:31.112573Z","iopub.status.idle":"2023-04-23T04:43:31.339027Z","shell.execute_reply.started":"2023-04-23T04:43:31.112540Z","shell.execute_reply":"2023-04-23T04:43:31.337773Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Model: \"my_model\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n layer1 (Dense)              (None, 20)                380       \n                                                                 \n layer2 (Dense)              (None, 10)                210       \n                                                                 \n layer3 (Dense)              (None, 5)                 55        \n                                                                 \n layer4 (Dense)              (None, 1)                 6         \n                                                                 \n=================================================================\nTotal params: 651\nTrainable params: 651\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"\nmodel.compile(loss=tf.keras.losses.MeanSquaredError(),\n              optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005))","metadata":{"execution":{"iopub.status.busy":"2023-04-23T04:43:31.340413Z","iopub.execute_input":"2023-04-23T04:43:31.341319Z","iopub.status.idle":"2023-04-23T04:43:31.364472Z","shell.execute_reply.started":"2023-04-23T04:43:31.341268Z","shell.execute_reply":"2023-04-23T04:43:31.363280Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"history = model.fit(\n    x_train,y_train,\n    validation_data=(x_test, y_test),\n    batch_size=16,\n    epochs=100\n)","metadata":{"execution":{"iopub.status.busy":"2023-04-23T04:43:31.365730Z","iopub.execute_input":"2023-04-23T04:43:31.366117Z","iopub.status.idle":"2023-04-23T04:43:53.003702Z","shell.execute_reply.started":"2023-04-23T04:43:31.366083Z","shell.execute_reply":"2023-04-23T04:43:53.002461Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Epoch 1/100\n74/74 [==============================] - 1s 5ms/step - loss: 38730801152.0000 - val_loss: 37947224064.0000\nEpoch 2/100\n74/74 [==============================] - 0s 2ms/step - loss: 37569511424.0000 - val_loss: 36347084800.0000\nEpoch 3/100\n74/74 [==============================] - 0s 2ms/step - loss: 34872135680.0000 - val_loss: 32214267904.0000\nEpoch 4/100\n74/74 [==============================] - 0s 2ms/step - loss: 28619929600.0000 - val_loss: 23953160192.0000\nEpoch 5/100\n74/74 [==============================] - 0s 2ms/step - loss: 19209449472.0000 - val_loss: 14043261952.0000\nEpoch 6/100\n74/74 [==============================] - 0s 3ms/step - loss: 11663775744.0000 - val_loss: 8258287616.0000\nEpoch 7/100\n74/74 [==============================] - 0s 2ms/step - loss: 8424787456.0000 - val_loss: 6514083840.0000\nEpoch 8/100\n74/74 [==============================] - 0s 2ms/step - loss: 7328260608.0000 - val_loss: 5792567808.0000\nEpoch 9/100\n74/74 [==============================] - 0s 2ms/step - loss: 6798306816.0000 - val_loss: 5474073088.0000\nEpoch 10/100\n74/74 [==============================] - 0s 2ms/step - loss: 6351721984.0000 - val_loss: 5260064256.0000\nEpoch 11/100\n74/74 [==============================] - 0s 2ms/step - loss: 6003307520.0000 - val_loss: 5093791232.0000\nEpoch 12/100\n74/74 [==============================] - 0s 2ms/step - loss: 5702994944.0000 - val_loss: 4941076480.0000\nEpoch 13/100\n74/74 [==============================] - 0s 5ms/step - loss: 5395194368.0000 - val_loss: 4822897664.0000\nEpoch 14/100\n74/74 [==============================] - 0s 3ms/step - loss: 5165507072.0000 - val_loss: 4712531456.0000\nEpoch 15/100\n74/74 [==============================] - 0s 2ms/step - loss: 4932021248.0000 - val_loss: 4615424512.0000\nEpoch 16/100\n74/74 [==============================] - 0s 2ms/step - loss: 4726977024.0000 - val_loss: 4531502080.0000\nEpoch 17/100\n74/74 [==============================] - 0s 2ms/step - loss: 4545641984.0000 - val_loss: 4441203200.0000\nEpoch 18/100\n74/74 [==============================] - 0s 2ms/step - loss: 4368390144.0000 - val_loss: 4360636928.0000\nEpoch 19/100\n74/74 [==============================] - 0s 2ms/step - loss: 4209564672.0000 - val_loss: 4295974912.0000\nEpoch 20/100\n74/74 [==============================] - 0s 2ms/step - loss: 4084629504.0000 - val_loss: 4231696640.0000\nEpoch 21/100\n74/74 [==============================] - 0s 2ms/step - loss: 3954931712.0000 - val_loss: 4160866048.0000\nEpoch 22/100\n74/74 [==============================] - 0s 3ms/step - loss: 3833149952.0000 - val_loss: 4097255168.0000\nEpoch 23/100\n74/74 [==============================] - 0s 3ms/step - loss: 3715505664.0000 - val_loss: 4034360064.0000\nEpoch 24/100\n74/74 [==============================] - 0s 2ms/step - loss: 3615800320.0000 - val_loss: 3977183232.0000\nEpoch 25/100\n74/74 [==============================] - 0s 2ms/step - loss: 3513530880.0000 - val_loss: 3915611904.0000\nEpoch 26/100\n74/74 [==============================] - 0s 2ms/step - loss: 3416588288.0000 - val_loss: 3873019136.0000\nEpoch 27/100\n74/74 [==============================] - 0s 2ms/step - loss: 3345782016.0000 - val_loss: 3821741824.0000\nEpoch 28/100\n74/74 [==============================] - 0s 3ms/step - loss: 3273945856.0000 - val_loss: 3760896768.0000\nEpoch 29/100\n74/74 [==============================] - 0s 2ms/step - loss: 3217448704.0000 - val_loss: 3725486336.0000\nEpoch 30/100\n74/74 [==============================] - 0s 2ms/step - loss: 3173127424.0000 - val_loss: 3736899584.0000\nEpoch 31/100\n74/74 [==============================] - 0s 2ms/step - loss: 3124128256.0000 - val_loss: 3674593024.0000\nEpoch 32/100\n74/74 [==============================] - 0s 2ms/step - loss: 3075967232.0000 - val_loss: 3655479552.0000\nEpoch 33/100\n74/74 [==============================] - 0s 2ms/step - loss: 3035278080.0000 - val_loss: 3624761344.0000\nEpoch 34/100\n74/74 [==============================] - 0s 2ms/step - loss: 3002098176.0000 - val_loss: 3583212800.0000\nEpoch 35/100\n74/74 [==============================] - 0s 2ms/step - loss: 2957229824.0000 - val_loss: 3563584512.0000\nEpoch 36/100\n74/74 [==============================] - 0s 3ms/step - loss: 2916750592.0000 - val_loss: 3549924608.0000\nEpoch 37/100\n74/74 [==============================] - 0s 2ms/step - loss: 2879810304.0000 - val_loss: 3513097728.0000\nEpoch 38/100\n74/74 [==============================] - 0s 2ms/step - loss: 2837428992.0000 - val_loss: 3526051840.0000\nEpoch 39/100\n74/74 [==============================] - 0s 2ms/step - loss: 2801528832.0000 - val_loss: 3477355520.0000\nEpoch 40/100\n74/74 [==============================] - 0s 2ms/step - loss: 2765972480.0000 - val_loss: 3434827520.0000\nEpoch 41/100\n74/74 [==============================] - 0s 3ms/step - loss: 2734925568.0000 - val_loss: 3465180928.0000\nEpoch 42/100\n74/74 [==============================] - 0s 2ms/step - loss: 2692927488.0000 - val_loss: 3429027328.0000\nEpoch 43/100\n74/74 [==============================] - 0s 2ms/step - loss: 2656290304.0000 - val_loss: 3437716992.0000\nEpoch 44/100\n74/74 [==============================] - 0s 3ms/step - loss: 2620546560.0000 - val_loss: 3398052352.0000\nEpoch 45/100\n74/74 [==============================] - 0s 2ms/step - loss: 2583278592.0000 - val_loss: 3369822976.0000\nEpoch 46/100\n74/74 [==============================] - 0s 2ms/step - loss: 2545344256.0000 - val_loss: 3361172224.0000\nEpoch 47/100\n74/74 [==============================] - 0s 2ms/step - loss: 2509473280.0000 - val_loss: 3415549952.0000\nEpoch 48/100\n74/74 [==============================] - 0s 2ms/step - loss: 2475525632.0000 - val_loss: 3331336960.0000\nEpoch 49/100\n74/74 [==============================] - 0s 2ms/step - loss: 2433085696.0000 - val_loss: 3339862016.0000\nEpoch 50/100\n74/74 [==============================] - 0s 2ms/step - loss: 2394470144.0000 - val_loss: 3318969856.0000\nEpoch 51/100\n74/74 [==============================] - 0s 2ms/step - loss: 2357516032.0000 - val_loss: 3305692928.0000\nEpoch 52/100\n74/74 [==============================] - 0s 2ms/step - loss: 2316169728.0000 - val_loss: 3422819584.0000\nEpoch 53/100\n74/74 [==============================] - 0s 2ms/step - loss: 2286553344.0000 - val_loss: 3295782656.0000\nEpoch 54/100\n74/74 [==============================] - 0s 2ms/step - loss: 2264941312.0000 - val_loss: 3242270208.0000\nEpoch 55/100\n74/74 [==============================] - 0s 2ms/step - loss: 2199635968.0000 - val_loss: 3290759936.0000\nEpoch 56/100\n74/74 [==============================] - 0s 3ms/step - loss: 2169829120.0000 - val_loss: 3267114752.0000\nEpoch 57/100\n74/74 [==============================] - 0s 2ms/step - loss: 2129264384.0000 - val_loss: 3311991552.0000\nEpoch 58/100\n74/74 [==============================] - 0s 3ms/step - loss: 2104757248.0000 - val_loss: 3341362176.0000\nEpoch 59/100\n74/74 [==============================] - 0s 3ms/step - loss: 2065629312.0000 - val_loss: 3286856192.0000\nEpoch 60/100\n74/74 [==============================] - 0s 2ms/step - loss: 2038028672.0000 - val_loss: 3282944512.0000\nEpoch 61/100\n74/74 [==============================] - 0s 3ms/step - loss: 2023769600.0000 - val_loss: 3318091776.0000\nEpoch 62/100\n74/74 [==============================] - 0s 2ms/step - loss: 1997305344.0000 - val_loss: 3415477248.0000\nEpoch 63/100\n74/74 [==============================] - 0s 2ms/step - loss: 1970424320.0000 - val_loss: 3338577920.0000\nEpoch 64/100\n74/74 [==============================] - 0s 2ms/step - loss: 1943782528.0000 - val_loss: 3304043520.0000\nEpoch 65/100\n74/74 [==============================] - 0s 2ms/step - loss: 1947999616.0000 - val_loss: 3354828032.0000\nEpoch 66/100\n74/74 [==============================] - 0s 2ms/step - loss: 1920399488.0000 - val_loss: 3339807232.0000\nEpoch 67/100\n74/74 [==============================] - 0s 2ms/step - loss: 1907589248.0000 - val_loss: 3367196928.0000\nEpoch 68/100\n74/74 [==============================] - 0s 3ms/step - loss: 1886701312.0000 - val_loss: 3530589440.0000\nEpoch 69/100\n74/74 [==============================] - 0s 2ms/step - loss: 1876667904.0000 - val_loss: 3550155264.0000\nEpoch 70/100\n74/74 [==============================] - 0s 3ms/step - loss: 1867690880.0000 - val_loss: 3390771968.0000\nEpoch 71/100\n74/74 [==============================] - 0s 3ms/step - loss: 1868514944.0000 - val_loss: 3581800960.0000\nEpoch 72/100\n74/74 [==============================] - 0s 2ms/step - loss: 1846887424.0000 - val_loss: 3570927872.0000\nEpoch 73/100\n74/74 [==============================] - 0s 2ms/step - loss: 1829078784.0000 - val_loss: 3435303168.0000\nEpoch 74/100\n74/74 [==============================] - 0s 2ms/step - loss: 1836818816.0000 - val_loss: 3589000704.0000\nEpoch 75/100\n74/74 [==============================] - 0s 2ms/step - loss: 1836663424.0000 - val_loss: 3625975296.0000\nEpoch 76/100\n74/74 [==============================] - 0s 3ms/step - loss: 1822401024.0000 - val_loss: 3474141952.0000\nEpoch 77/100\n74/74 [==============================] - 0s 2ms/step - loss: 1821567488.0000 - val_loss: 3732726272.0000\nEpoch 78/100\n74/74 [==============================] - 0s 2ms/step - loss: 1810254464.0000 - val_loss: 3563629056.0000\nEpoch 79/100\n74/74 [==============================] - 0s 2ms/step - loss: 1820495488.0000 - val_loss: 3613963520.0000\nEpoch 80/100\n74/74 [==============================] - 0s 2ms/step - loss: 1807626752.0000 - val_loss: 3708312320.0000\nEpoch 81/100\n74/74 [==============================] - 0s 2ms/step - loss: 1804809472.0000 - val_loss: 3562790400.0000\nEpoch 82/100\n74/74 [==============================] - 0s 2ms/step - loss: 1804453760.0000 - val_loss: 3745616128.0000\nEpoch 83/100\n74/74 [==============================] - 0s 2ms/step - loss: 1808753664.0000 - val_loss: 3667444736.0000\nEpoch 84/100\n74/74 [==============================] - 0s 2ms/step - loss: 1802024960.0000 - val_loss: 3628204800.0000\nEpoch 85/100\n74/74 [==============================] - 0s 3ms/step - loss: 1793990528.0000 - val_loss: 3705999360.0000\nEpoch 86/100\n74/74 [==============================] - 0s 2ms/step - loss: 1814943744.0000 - val_loss: 3711241216.0000\nEpoch 87/100\n74/74 [==============================] - 0s 2ms/step - loss: 1802883840.0000 - val_loss: 3587265792.0000\nEpoch 88/100\n74/74 [==============================] - 0s 2ms/step - loss: 1797279232.0000 - val_loss: 3564681728.0000\nEpoch 89/100\n74/74 [==============================] - 0s 2ms/step - loss: 1793325568.0000 - val_loss: 3655376384.0000\nEpoch 90/100\n74/74 [==============================] - 0s 2ms/step - loss: 1793602944.0000 - val_loss: 3653801472.0000\nEpoch 91/100\n74/74 [==============================] - 0s 2ms/step - loss: 1792505472.0000 - val_loss: 3629070336.0000\nEpoch 92/100\n74/74 [==============================] - 0s 2ms/step - loss: 1791797504.0000 - val_loss: 3647107072.0000\nEpoch 93/100\n74/74 [==============================] - 0s 2ms/step - loss: 1790408832.0000 - val_loss: 3579828736.0000\nEpoch 94/100\n74/74 [==============================] - 0s 2ms/step - loss: 1791059072.0000 - val_loss: 3687117824.0000\nEpoch 95/100\n74/74 [==============================] - 0s 2ms/step - loss: 1797356800.0000 - val_loss: 3716098304.0000\nEpoch 96/100\n74/74 [==============================] - 0s 2ms/step - loss: 1785366400.0000 - val_loss: 3609384448.0000\nEpoch 97/100\n74/74 [==============================] - 0s 2ms/step - loss: 1783091200.0000 - val_loss: 3658938624.0000\nEpoch 98/100\n74/74 [==============================] - 0s 2ms/step - loss: 1798329728.0000 - val_loss: 3711983360.0000\nEpoch 99/100\n74/74 [==============================] - 0s 2ms/step - loss: 1787439232.0000 - val_loss: 3744050944.0000\nEpoch 100/100\n74/74 [==============================] - 0s 2ms/step - loss: 1789667456.0000 - val_loss: 3626268416.0000\n","output_type":"stream"}]},{"cell_type":"code","source":"test_loss = model.evaluate(x_test, y_test,)","metadata":{"execution":{"iopub.status.busy":"2023-04-23T04:43:53.005301Z","iopub.execute_input":"2023-04-23T04:43:53.005637Z","iopub.status.idle":"2023-04-23T04:43:53.096689Z","shell.execute_reply.started":"2023-04-23T04:43:53.005596Z","shell.execute_reply":"2023-04-23T04:43:53.095352Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"9/9 [==============================] - 0s 2ms/step - loss: 3626268160.0000\n","output_type":"stream"}]},{"cell_type":"code","source":"p = model.predict(x_test)\nfrom sklearn.metrics import mean_absolute_error\n\n# assume y_true and y_pred are your ground truth and predicted values, respectively\nmae = mean_absolute_error(y_test, p)\n\nprint(f\"MAE: {mae}\")\nmse = tf.keras.losses.mean_squared_error(y_test, p)\nprint(\"MSE: \", mse)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-23T04:43:53.098328Z","iopub.execute_input":"2023-04-23T04:43:53.098694Z","iopub.status.idle":"2023-04-23T04:43:53.648182Z","shell.execute_reply.started":"2023-04-23T04:43:53.098658Z","shell.execute_reply":"2023-04-23T04:43:53.646800Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"9/9 [==============================] - 0s 1ms/step\nMAE: 32991.733432583045\nMSE:  tf.Tensor(\n[9.3659402e+09 2.8355516e+10 1.1718428e+10 9.5933655e+09 9.0153687e+09\n 2.2495461e+10 1.7807499e+10 7.4707302e+09 1.0770937e+11 6.2096660e+09\n 1.3089889e+10 8.1558707e+09 6.1563756e+09 1.0079010e+10 6.1462764e+09\n 6.4369295e+09 1.4161638e+10 6.7980733e+09 7.7002772e+09 6.7707453e+09\n 8.3897595e+09 6.9650826e+09 7.3892946e+09 6.4396979e+09 6.2187776e+09\n 6.2903665e+09 1.2164841e+10 6.4540841e+09 8.0487235e+09 7.6636237e+09\n 7.2707676e+09 2.4246284e+10 8.0694799e+09 9.0761830e+09 6.7461033e+09\n 8.3507840e+09 6.8702080e+09 6.1837000e+09 1.7608808e+10 1.2198842e+10\n 1.0183550e+10 1.0563403e+10 6.8042061e+09 6.1514583e+09 2.7219397e+10\n 1.3720499e+10 1.1183900e+10 7.9610665e+09 6.3716654e+09 1.9182998e+10\n 6.5615729e+09 1.1660860e+10 7.9656479e+09 8.5612974e+09 1.4380971e+10\n 6.2121677e+09 2.0531687e+10 6.5969270e+09 1.3670184e+10 6.3223076e+09\n 6.1756979e+09 6.3764485e+09 6.3054556e+09 6.6656630e+09 6.6908201e+09\n 6.5480248e+09 6.4126935e+09 1.3378113e+10 6.7784776e+09 2.3430224e+10\n 6.4749020e+09 6.1509023e+09 6.1523210e+09 6.2515610e+09 6.5678669e+09\n 1.0779817e+10 1.8319661e+10 6.1652936e+09 1.1913828e+10 1.0525514e+10\n 6.2835026e+09 6.3949542e+09 1.7692979e+10 1.6333254e+10 8.3832755e+09\n 7.5838500e+09 6.2434278e+09 8.4179948e+09 6.3145646e+09 6.3490647e+09\n 6.1497247e+09 6.9159875e+09 6.2101366e+09 1.9241224e+10 3.8715965e+10\n 6.5287608e+09 7.0632668e+09 6.5789076e+09 1.0441182e+10 6.9799880e+09\n 7.6044539e+09 6.6004854e+09 6.7328031e+09 8.9723648e+09 9.0803978e+09\n 8.3395246e+09 7.6154834e+09 6.1448847e+09 7.6562063e+09 6.5014200e+09\n 8.6335222e+09 7.6421919e+09 6.1643709e+09 7.8893824e+09 7.2169293e+09\n 9.8252677e+09 6.6707333e+09 1.0032577e+10 9.9241667e+09 6.1707622e+09\n 9.2755784e+09 8.8361042e+09 6.7158170e+09 1.0841958e+10 4.5386108e+11\n 6.7665843e+09 7.4499968e+09 7.5285443e+09 1.9963245e+10 1.0458369e+10\n 6.1465933e+09 1.1455072e+10 6.1456968e+09 8.2738171e+09 7.3144801e+09\n 6.1696748e+09 1.3874198e+10 6.1726423e+09 2.8080495e+10 2.3737434e+10\n 1.0571865e+10 8.8359834e+09 1.1010723e+10 6.1537556e+09 1.3032630e+10\n 1.1449138e+10 6.4597110e+09 2.5334032e+10 6.6891448e+09 2.5217018e+10\n 1.5194336e+10 1.8305135e+10 2.2223860e+10 1.3690013e+10 2.4082684e+10\n 6.1489249e+09 9.9580488e+09 8.3282340e+09 1.3103739e+10 7.7634524e+09\n 7.4671877e+09 6.3312497e+09 8.1135375e+09 2.1543530e+10 6.7262464e+09\n 1.2055016e+10 1.0039071e+10 6.5378299e+09 1.2388359e+10 6.3229926e+09\n 6.7339484e+09 1.0210449e+10 1.3479090e+10 1.2287967e+10 6.8955520e+09\n 6.1540925e+09 2.5683317e+10 6.2027208e+09 7.5230700e+09 5.0629042e+10\n 9.0039972e+09 6.1771110e+09 1.1991448e+10 7.0996029e+09 6.5630525e+09\n 1.9036684e+10 1.1912145e+10 6.8467098e+09 6.2202783e+09 7.4069571e+09\n 9.5739689e+09 6.3346903e+09 6.6054282e+09 7.4682184e+09 1.1707928e+10\n 8.4277012e+09 7.3283231e+09 6.1509350e+09 9.6414822e+09 4.5964182e+10\n 1.1094270e+10 8.8551997e+09 1.5943158e+10 6.5008369e+09 1.5350955e+10\n 9.0092728e+09 1.3206872e+10 9.9874109e+09 6.1470474e+09 6.2156375e+09\n 1.0002570e+10 1.0101559e+10 2.1114841e+10 7.9310822e+09 1.2570375e+10\n 8.1997727e+09 7.1268301e+09 9.3182781e+09 1.2040967e+10 6.2628859e+09\n 6.6426573e+09 1.5335969e+10 6.6539377e+09 7.0713078e+09 6.6366003e+09\n 6.4656481e+09 9.8732175e+09 6.2878193e+09 6.2051927e+09 7.9944417e+09\n 6.2271150e+09 7.3083192e+09 1.3275398e+10 1.6834987e+10 7.1995412e+09\n 7.8748867e+09 7.2506860e+09 6.3475876e+09 1.7231196e+10 1.2747494e+10\n 6.2228326e+09 7.0138962e+09 8.7502797e+09 2.4977363e+10 7.3973151e+09\n 1.2193407e+10 6.1512755e+09 7.9954463e+09 1.1702555e+10 6.5409183e+09\n 6.3813535e+09 6.1746412e+09 1.0214883e+10 6.4491832e+09 1.4398813e+10\n 6.3963607e+09 6.1913482e+09 9.4722427e+09 1.3553187e+10 6.3656489e+09\n 6.6877763e+09 6.3479583e+09 9.6170435e+09 1.7264169e+10 6.1493176e+09\n 6.1735409e+09 9.4321900e+09 1.1707209e+10 1.0352970e+10 1.1371857e+10\n 6.6974423e+09 1.2850460e+10 6.7306624e+09 1.0057344e+10 8.3292918e+09\n 2.5397064e+10 6.6592983e+09 9.8586993e+09 1.0849519e+10 9.5839160e+09\n 6.5934710e+09 6.1574144e+09 1.1611025e+10 9.2562299e+09 8.8058409e+09\n 6.7451028e+09], shape=(286,), dtype=float32)\n","output_type":"stream"}]},{"cell_type":"code","source":"test = pd.read_csv(\"https://raw.githubusercontent.com/Rahulsharma869/Housing-Price-Prediction/main/Datasets/test.csv\")\ntest_data=test.loc[:,xtrain_col]\npredicted_prices = model.predict(test_data)\n\n# Create a dataframe with the predicted prices and the corresponding IDs\nsubmission_df = pd.DataFrame({'Id': test.Id, 'SalePrice': predicted_prices.flatten()})\n\n# Save the dataframe to a CSV file\nsubmission_df.to_csv('submission.csv', index=False)\nsubmission_df","metadata":{"execution":{"iopub.status.busy":"2023-04-23T04:43:53.649633Z","iopub.execute_input":"2023-04-23T04:43:53.649997Z","iopub.status.idle":"2023-04-23T04:43:54.111888Z","shell.execute_reply.started":"2023-04-23T04:43:53.649961Z","shell.execute_reply":"2023-04-23T04:43:54.110687Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"46/46 [==============================] - 0s 1ms/step\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"        Id      SalePrice\n0     1461  141695.984375\n1     1462  170646.265625\n2     1463  185429.359375\n3     1464  180771.000000\n4     1465  171490.953125\n...    ...            ...\n1454  2915   76439.812500\n1455  2916   98173.000000\n1456  2917  178402.359375\n1457  2918   90945.125000\n1458  2919  230946.875000\n\n[1459 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>SalePrice</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1461</td>\n      <td>141695.984375</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1462</td>\n      <td>170646.265625</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1463</td>\n      <td>185429.359375</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1464</td>\n      <td>180771.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1465</td>\n      <td>171490.953125</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1454</th>\n      <td>2915</td>\n      <td>76439.812500</td>\n    </tr>\n    <tr>\n      <th>1455</th>\n      <td>2916</td>\n      <td>98173.000000</td>\n    </tr>\n    <tr>\n      <th>1456</th>\n      <td>2917</td>\n      <td>178402.359375</td>\n    </tr>\n    <tr>\n      <th>1457</th>\n      <td>2918</td>\n      <td>90945.125000</td>\n    </tr>\n    <tr>\n      <th>1458</th>\n      <td>2919</td>\n      <td>230946.875000</td>\n    </tr>\n  </tbody>\n</table>\n<p>1459 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"test = pd.read_csv(\"https://raw.githubusercontent.com/Rahulsharma869/Housing-Price-Prediction/main/Datasets/test.csv\")\ntest_data=test.loc[:,xtrain_col]","metadata":{"execution":{"iopub.status.busy":"2023-04-23T04:43:54.115073Z","iopub.execute_input":"2023-04-23T04:43:54.115419Z","iopub.status.idle":"2023-04-23T04:43:54.245610Z","shell.execute_reply.started":"2023-04-23T04:43:54.115384Z","shell.execute_reply":"2023-04-23T04:43:54.244162Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"predicted_prices = model.predict(test_data)\n\n# Create a dataframe with the predicted prices and the corresponding IDs\nsubmission_df = pd.DataFrame({'Id': test.Id, 'SalePrice': predicted_prices.flatten()})\n\n# Save the dataframe to a CSV file\nsubmission_df.to_csv('submission.csv', index=False)\nsubmission_df","metadata":{"execution":{"iopub.status.busy":"2023-04-23T04:49:09.516855Z","iopub.execute_input":"2023-04-23T04:49:09.517289Z","iopub.status.idle":"2023-04-23T04:49:09.689500Z","shell.execute_reply.started":"2023-04-23T04:49:09.517250Z","shell.execute_reply":"2023-04-23T04:49:09.688252Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"46/46 [==============================] - 0s 1ms/step\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"        Id      SalePrice\n0     1461  141695.984375\n1     1462  170646.265625\n2     1463  185429.359375\n3     1464  180771.000000\n4     1465  171490.953125\n...    ...            ...\n1454  2915   76439.812500\n1455  2916   98173.000000\n1456  2917  178402.359375\n1457  2918   90945.125000\n1458  2919  230946.875000\n\n[1459 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>SalePrice</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1461</td>\n      <td>141695.984375</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1462</td>\n      <td>170646.265625</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1463</td>\n      <td>185429.359375</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1464</td>\n      <td>180771.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1465</td>\n      <td>171490.953125</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1454</th>\n      <td>2915</td>\n      <td>76439.812500</td>\n    </tr>\n    <tr>\n      <th>1455</th>\n      <td>2916</td>\n      <td>98173.000000</td>\n    </tr>\n    <tr>\n      <th>1456</th>\n      <td>2917</td>\n      <td>178402.359375</td>\n    </tr>\n    <tr>\n      <th>1457</th>\n      <td>2918</td>\n      <td>90945.125000</td>\n    </tr>\n    <tr>\n      <th>1458</th>\n      <td>2919</td>\n      <td>230946.875000</td>\n    </tr>\n  </tbody>\n</table>\n<p>1459 rows × 2 columns</p>\n</div>"},"metadata":{}}]}]}